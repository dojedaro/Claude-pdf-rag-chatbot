# Claude PDF RAG Chatbot

An end-to-end **retrieval-augmented generation (RAG)** application that allows users to upload PDF documents and ask natural language questions, with answers generated by **Anthropic Claude** and grounded in retrieved document context.

This project demonstrates how to build a **deployable, source-aware document QA system** using modern LLM tooling.

---

## ğŸ” Use Case

- Ask questions about research papers, reports, or internal documents  
- Enable document understanding without manual searching  
- Provide **transparent, source-grounded answers** for higher trust  

This pattern is applicable to enterprise knowledge bases, compliance review, and research workflows.

---

## ğŸ§  System Overview

The application follows a standard RAG pipeline:

1. **PDF Ingestion** â€“ Users upload one or more PDF files
2. **Chunking** â€“ Documents are split into overlapping text chunks
3. **Embedding** â€“ Text chunks are embedded using a Hugging Face sentence-transformer
4. **Vector Search** â€“ Relevant chunks are retrieved from a Chroma vector store
5. **Generation** â€“ Claude generates answers using only retrieved context
6. **Source Display** â€“ Retrieved document excerpts and page numbers are shown to the user

---

## ğŸ§© Key Technologies

- **Streamlit** â€“ Interactive chat-based user interface
- **LangChain** â€“ Document loading, chunking, and retrieval orchestration
- **ChromaDB** â€“ Vector database for semantic search
- **Hugging Face Embeddings** â€“ `all-MiniLM-L6-v2`
- **Anthropic Claude** â€“ LLM for grounded answer generation

---

## ğŸ” Environment Setup

This project uses environment variables for API keys.

Create a `.env` file locally (or use Streamlit Secrets) with:

```env
ANTHROPIC_API_KEY=your_anthropic_api_key_here
